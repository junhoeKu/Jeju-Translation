{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets>=2.6.1\n!pip install git+https://github.com/huggingface/transformers\n!pip install evaluate>=0.30\n!pip install jiwer\n!pip install accelerate -U\n!pip install transformers[torch]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-26T18:19:16.306512Z","iopub.execute_input":"2024-05-26T18:19:16.307112Z","iopub.status.idle":"2024-05-26T18:21:16.281332Z","shell.execute_reply.started":"2024-05-26T18:19:16.307082Z","shell.execute_reply":"2024-05-26T18:21:16.279856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\naccess_token_write = \"hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\nlogin(token = access_token_write)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\nlow_call_voices_prepreocessed = load_dataset(\"xxxxxxx/working\")\nlow_call_voices_prepreocessed","metadata":{"execution":{"iopub.status.busy":"2024-05-26T18:21:16.284364Z","iopub.execute_input":"2024-05-26T18:21:16.284928Z","iopub.status.idle":"2024-05-26T18:22:52.111536Z","shell.execute_reply.started":"2024-05-26T18:21:16.284878Z","shell.execute_reply":"2024-05-26T18:22:52.110035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # 인풋 데이터와 라벨 데이터의 길이가 다르며, 따라서 서로 다른 패딩 방법이 적용되어야 한다. 그러므로 두 데이터를 분리해야 한다.\n        # 먼저 오디오 인풋 데이터를 간단히 토치 텐서로 반환하는 작업을 수행한다.\n        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n\n        # Tokenize된 레이블 시퀀스를 가져온다.\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        # 레이블 시퀀스에 대해 최대 길이만큼 패딩 작업을 실시한다.\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n\n        # 패딩 토큰을 -100으로 치환하여 loss 계산 과정에서 무시되도록 한다.\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        # 이전 토크나이즈 과정에서 bos 토큰이 추가되었다면 bos 토큰을 잘라낸다.\n        # 해당 토큰은 이후 언제든 추가할 수 있다.\n        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n\n        batch[\"labels\"] = labels\n\n        return batch","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 훈련시킬 모델의 processor, tokenizer, feature extractor 로드\nfrom transformers import WhisperTokenizer,  WhisperFeatureExtractor\nfrom transformers import WhisperProcessor\n\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v2\", language=\"Korean\", task=\"transcribe\")\ntokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-large-v2\", language=\"Korean\", task=\"transcribe\")\nfeature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large-v2\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 데이터 콜레이터 초기화\ndata_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load('cer')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n\n    # pad_token을 -100으로 치환\n    label_ids[label_ids == -100] = tokenizer.pad_token_id\n\n    # metrics 계산 시 special token들을 빼고 계산하도록 설정\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n\n    cer = 100 * metric.compute(predictions=pred_str, references=label_str)\n\n    return {\"cer\": cer}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import WhisperForConditionalGeneration\n\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v2\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"xxxxxxxxxxxx\",  # 원하는 리포지토리 이름을 임력한다.\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=1,  # 배치 크기가 2배 감소할 때마다 2배씩 증가\n    learning_rate=1e-5,\n    warmup_steps=500,\n    max_steps=4000,  # epoch 대신 설정\n    gradient_checkpointing=True,\n    fp16=True,\n    evaluation_strategy=\"steps\",\n    per_device_eval_batch_size=8,\n    predict_with_generate=True,\n    generation_max_length=225,\n    save_steps=1000,\n    eval_steps=1000,\n    logging_steps=25,\n    report_to=[\"tensorboard\"],\n    load_best_model_at_end=True,\n    metric_for_best_model=\"cer\",  # 한국어의 경우 'wer'보다는 'cer'이 더 적합할 것\n    greater_is_better=False,\n    push_to_hub=True,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=low_call_voices_prepreocessed[\"train\"],\n    eval_dataset=low_call_voices_prepreocessed[\"valid\"],  # or \"test\"\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor.feature_extractor,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{},"execution_count":null,"outputs":[]}]}