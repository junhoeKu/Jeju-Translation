{"cells":[{"cell_type":"code","execution_count":null,"id":"bc78e473","metadata":{"id":"bc78e473"},"outputs":[],"source":["import transformers\n","import torch\n","import pandas as pd\n","import numpy as np\n","import os\n","from transformers import AutoModelForCausalLM, AutoTokenizer, AdamW, BitsAndBytesConfig\n","from tqdm.notebook import tqdm\n","from nltk.translate.bleu_score import sentence_bleu\n","import requests\n","import requests\n","\n","API_URL = \"https://api-inference.huggingface.co/models/openai/whisper-large-v2\"\n","headers = {\"Authorization\": \"Bearer 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\"}\n","\n","def query(filename):\n","    with open(filename, \"rb\") as f:\n","        data = f.read()\n","    response = requests.post(API_URL, headers=headers, data=data)\n","    return response.json()\n","\n","#output = query(\"sample1.flac\")"]},{"cell_type":"code","execution_count":null,"id":"2e23b949","metadata":{"id":"2e23b949","outputId":"a2bb799e-330f-4c90-d97d-07bf41f2aae1"},"outputs":[{"name":"stdout","output_type":"stream","text":["say something\n"]},{"name":"stderr","output_type":"stream","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]},{"name":"stdout","output_type":"stream","text":["Your speech thinks like:   자기가 말로 하면 들을 아이가 어디가 말 듣게 생기시니 자이가.\n"]},{"name":"stderr","output_type":"stream","text":["Your input_length: 20 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n","C:\\Users\\lg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation\\utils.py:1201: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["제주어 -> 표준어: 쟤가 말로 하면 들을 아이가 어디가 말 듣게 생기니 쟤가.\n"]}],"source":["import speech_recognition as sr\n","\n","def get_audio():\n","    r = sr.Recognizer()\n","    with sr.Microphone() as source:\n","\n","        #음성 입력\n","        audio = r.listen(source)\n","        with open(\"microphone-results.wav\", \"wb\") as f:\n","            f.write(audio.get_wav_data())\n","        said = \" \"\n","\n","        try:\n","            #음성 인식\n","            said = query(\"microphone-results.wav\")['text']\n","            print(\"Your speech thinks like: \", said)\n","\n","        except Exception as e:\n","            print(\"Exception: \" + str(e))\n","        os.remove(\"microphone-results.wav\")\n","    return said\n","\n","text1 = get_audio()\n","\n","\n","from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast\n","\n","# 모델과 토크나이저의 경로\n","model_path = 'C:/nonsaso/비타민/nlp/0526_checkpoint_118000/'\n","\n","# 모델과 토크나이저 로드\n","model = BartForConditionalGeneration.from_pretrained(model_path)\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(model_path)\n","\n","\n","from transformers import pipeline\n","\n","# 번역을 위한 파이프라인 생성\n","translation_pipeline = pipeline(\n","    \"translation_xx_to_yy\",\n","    model=model,\n","    tokenizer=tokenizer\n",")\n","\n","jeju_token = \"[제주]\"\n","standard_token = \"[표준]\"\n","\n","#음성으로 입력받았던 문장 번역\n","input_sentence =  text1\n","translated_sentence = translation_pipeline(jeju_token + \" \" + input_sentence)[0]['translation_text']\n","print(\"제주어 -> 표준어:\", translated_sentence)\n","\n","from gtts import gTTS\n","import os\n","import playsound\n","\n","def speak(text):\n","    tts = gTTS(text=text, lang='ko')\n","    filename = 'voice1.mp3'\n","    tts.save(filename)\n","    playsound.playsound(filename)\n","    os.remove(filename)\n","\n","speak(translated_sentence)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}